{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Install Required Libraries"
      ],
      "metadata": {
        "id": "-fDBEnyLe587"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi nest-asyncio uvicorn aiofiles transformers accelerate gradio pyngrok\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EAqdh2ALe-UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Enter Hugging Face Token"
      ],
      "metadata": {
        "id": "YbD9CCRnfBEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your Hugging Face token securely\n",
        "HUGGINGFACE_TOKEN = \"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\"\n"
      ],
      "metadata": {
        "id": "qqyyaFlxfEP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Import Libraries and Setup FastAPI App"
      ],
      "metadata": {
        "id": "PUt4eJrUfGv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, Request\n",
        "from fastapi.responses import HTMLResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import uvicorn\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# CORS configuration\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "LoFR7FOzfJ-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Load IBM Granite Model from Hugging Face\n"
      ],
      "metadata": {
        "id": "ZzAunalnfMbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import torch\n",
        "\n",
        "model_id = \"ibm-granite/granite-3.3-2b-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=HUGGINGFACE_TOKEN)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    use_auth_token=HUGGINGFACE_TOKEN\n",
        ")\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uoXZ13IyfREI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Chat API Endpoint"
      ],
      "metadata": {
        "id": "LT5AOE10fUdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class ChatInput(BaseModel):\n",
        "    query: str\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "async def generate_response(data: ChatInput):\n",
        "    prompt = f\"<|user|> {data.query.strip()} <|assistant|>\"\n",
        "    output = generator(prompt, max_new_tokens=150, do_sample=True, top_p=0.9, temperature=0.7)\n",
        "    reply = output[0]['generated_text'].split(\"<|assistant|>\")[-1].strip()\n",
        "    return {\"response\": reply}\n"
      ],
      "metadata": {
        "id": "ryF7afy2fYYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Sentiment Analysis API Endpoint"
      ],
      "metadata": {
        "id": "tx2mMZNJfa3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline as pipe\n",
        "\n",
        "sentiment_pipe = pipe(\"sentiment-analysis\")\n",
        "\n",
        "class SentimentInput(BaseModel):\n",
        "    text: str\n",
        "\n",
        "@app.post(\"/sentiment\")\n",
        "async def analyze_sentiment(data: SentimentInput):\n",
        "    result = sentiment_pipe(data.text)[0]\n",
        "    return {\"label\": result['label'], \"score\": round(result['score'], 2)}\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-RtaZquvfeRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7: Frontend UI (HTML + CSS Only for Chat and Sentiment)"
      ],
      "metadata": {
        "id": "iE1PSuLcfgyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi.responses import HTMLResponse\n",
        "\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def home():\n",
        "    return \"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "        <title>Citizen AI</title>\n",
        "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
        "        <style>\n",
        "            body {\n",
        "                font-family: Arial, sans-serif;\n",
        "                margin: 0;\n",
        "                padding: 20px;\n",
        "                background: #f4f4f4;\n",
        "                color: #333;\n",
        "            }\n",
        "            h2 {\n",
        "                color: #004aad;\n",
        "            }\n",
        "            .container {\n",
        "                max-width: 800px;\n",
        "                margin: auto;\n",
        "                background: white;\n",
        "                padding: 20px;\n",
        "                border-radius: 10px;\n",
        "                box-shadow: 0 0 15px rgba(0,0,0,0.1);\n",
        "            }\n",
        "            textarea, input, button {\n",
        "                width: 100%;\n",
        "                padding: 12px;\n",
        "                margin: 10px 0;\n",
        "                border-radius: 5px;\n",
        "                border: 1px solid #ccc;\n",
        "            }\n",
        "            button {\n",
        "                background-color: #004aad;\n",
        "                color: white;\n",
        "                border: none;\n",
        "                cursor: pointer;\n",
        "            }\n",
        "            button:hover {\n",
        "                background-color: #00307a;\n",
        "            }\n",
        "            pre {\n",
        "                background: #eef;\n",
        "                padding: 10px;\n",
        "                border-radius: 5px;\n",
        "                overflow-x: auto;\n",
        "            }\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <div class=\"container\">\n",
        "            <h2>💬 Citizen AI Chat</h2>\n",
        "            <input id=\"chatInput\" placeholder=\"Ask your question...\">\n",
        "            <button onclick=\"sendChat()\">Send</button>\n",
        "            <pre id=\"chatResponse\"></pre>\n",
        "\n",
        "            <h2>🧠 Sentiment Analysis</h2>\n",
        "            <textarea id=\"sentimentInput\" placeholder=\"Write your feedback here...\"></textarea>\n",
        "            <button onclick=\"sendSentiment()\">Analyze</button>\n",
        "            <pre id=\"sentimentResponse\"></pre>\n",
        "        </div>\n",
        "\n",
        "        <script>\n",
        "            async function sendChat() {\n",
        "                const input = document.getElementById(\"chatInput\").value;\n",
        "                const res = await fetch(\"/chat\", {\n",
        "                    method: \"POST\",\n",
        "                    headers: { \"Content-Type\": \"application/json\" },\n",
        "                    body: JSON.stringify({ query: input })\n",
        "                });\n",
        "                const data = await res.json();\n",
        "                document.getElementById(\"chatResponse\").textContent = \"AI: \" + data.response;\n",
        "            }\n",
        "\n",
        "            async function sendSentiment() {\n",
        "                const input = document.getElementById(\"sentimentInput\").value;\n",
        "                const res = await fetch(\"/sentiment\", {\n",
        "                    method: \"POST\",\n",
        "                    headers: { \"Content-Type\": \"application/json\" },\n",
        "                    body: JSON.stringify({ text: input })\n",
        "                });\n",
        "                const data = await res.json();\n",
        "                document.getElementById(\"sentimentResponse\").textContent =\n",
        "                    \"Sentiment: \" + data.label + \" (Score: \" + data.score + \")\";\n",
        "            }\n",
        "        </script>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "d0nTXHEffkCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8: Run FastAPI with Ngrok"
      ],
      "metadata": {
        "id": "tp5mXlTnfmYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "from threading import Thread\n",
        "import time\n",
        "\n",
        "nest_asyncio.apply()\n",
        "ngrok.set_auth_token(\"2z0J968W1nHr20Cxd0E4bZis5A0_3cYspaJAWZrGkMNLMpWZY\")\n",
        "\n",
        "ngrok.kill()\n",
        "time.sleep(2)\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"🌐 Citizen AI is running at:\", public_url)\n",
        "\n",
        "def start():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "Thread(target=start).start()\n"
      ],
      "metadata": {
        "id": "66NFR5qGfrBm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}